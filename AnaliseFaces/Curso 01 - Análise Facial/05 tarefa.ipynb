{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1f0973ac-5b3f-4e61-b4ed-003a8e7d6302",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "import numpy as np\n",
    "from scipy.spatial import distance as dist\n",
    "\n",
    "\n",
    "from io import BytesIO\n",
    "from IPython.display import clear_output, Image, display\n",
    "from PIL import Image as Img\n",
    "\n",
    "def padronizar_imagem(imagem):\n",
    "    imagem = cv2.cvtColor(imagem, cv2.COLOR_BGR2RGB)\n",
    "    imagem = cv2.resize(imagem, (800,600))\n",
    "    return imagem\n",
    "\n",
    "def exibir_video(frame):\n",
    "    img = Img.fromarray(frame, \"RGB\")\n",
    "    buffer = BytesIO()\n",
    "    img.save(buffer, format=\"JPEG\")\n",
    "    display(Image(data=buffer.getvalue()))\n",
    "    clear_output(wait=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de34f5b1-2406-466d-a415-3e92a6f95ce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interrompido\n"
     ]
    }
   ],
   "source": [
    "captura_video = cv2.VideoCapture(0)\n",
    "\n",
    "try:\n",
    "    while(True):\n",
    "        captura_ok, frame = captura_video.read()\n",
    "\n",
    "        if captura_ok:\n",
    "            frame = padronizar_imagem(frame)\n",
    "            exibir_video(frame)\n",
    "            \n",
    "except KeyboardInterrupt:\n",
    "    captura_video.release()\n",
    "    print(\"Interrompido\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341238f4-1201-4682-8665-990c923e9ee0",
   "metadata": {},
   "source": [
    "Se executar o código agora você verá a si mesmo renderizado no Notebook.\n",
    "\n",
    "O próximo passo é carregar o Dlib e os marcos faciais.\n",
    "\n",
    "Vamos carregar o classificador com 68 pontos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "80d9ea6e-56a9-42e5-a5a6-d3b6b64b6a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "classificador_dlib_68_pontos = \"classificadores/shape_predictor_68_face_landmarks.dat\"\n",
    "classificador_dlib = dlib.shape_predictor(classificador_dlib_68_pontos)\n",
    "detector_face = dlib.get_frontal_face_detector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab870bd8-be29-49be-a9fb-4e29380a265b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pontos_marcos_faciais(imagem):\n",
    "    retangulos = detector_face(imagem, 1)\n",
    "\n",
    "    if len(retangulos) == 0:\n",
    "        return None\n",
    "\n",
    "    marcos = []\n",
    "\n",
    "    for retangulo in retangulos:\n",
    "        marcos.append(np.matrix([[p.x, p.y] for p in classificador_dlib(imagem, retangulo).parts()]))\n",
    "\n",
    "    return marcos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c8aba06-7aa0-41f1-9695-f15fef13ce35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def anotar_marcos_faciais(imagem, marcos_faciais):\n",
    "    if imagem is None:\n",
    "        return im\n",
    "\n",
    "    for marco in marcos_faciais:\n",
    "        for idx, ponto in enumerate(marco):\n",
    "            centro = (ponto[0, 0], ponto[0, 1])\n",
    "            cv2.circle(imagem, centro, 3, color=(255, 255, 0), thickness=-1)\n",
    "    return imagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "99e0cc8e-38a1-45f1-a265-6012ee18c004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interrompido\n"
     ]
    }
   ],
   "source": [
    "captura_video = cv2.VideoCapture(0)\n",
    "\n",
    "try:\n",
    "    while(True):\n",
    "        captura_ok, frame = captura_video.read()\n",
    "\n",
    "        if captura_ok:\n",
    "            frame = padronizar_imagem(frame)\n",
    "            pontos = pontos_marcos_faciais(frame)\n",
    "            frame = anotar_marcos_faciais(frame, pontos)\n",
    "            exibir_video(frame)\n",
    "            \n",
    "except KeyboardInterrupt:\n",
    "    captura_video.release()\n",
    "    print(\"Interrompido\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5f090f-181c-49b9-a975-6d9f3d430c5a",
   "metadata": {},
   "source": [
    "Vamos definir as constantes das regiões do rosto. Bastaria somente do lábio, mas é sempre bom colocar todas elas, caso sejam necessárias outras regiões.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "171039a8-7fdf-418f-9f68-3e82da9a6486",
   "metadata": {},
   "outputs": [],
   "source": [
    "FACE = list(range(17, 68))\n",
    "FACE_COMPLETA = list(range(0, 68))\n",
    "LABIO = list(range(48, 61))\n",
    "SOMBRANCELHA_DIREITA = list(range(17, 22))\n",
    "SOMBRANCELHA_ESQUERDA = list(range(22, 27))\n",
    "OLHO_DIREITO = list(range(36, 42))\n",
    "OLHO_ESQUERDO = list(range(42, 48))\n",
    "NARIZ = list(range(27, 35))\n",
    "MANDIBULA = list(range(0, 17))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9301e673-6515-404c-ae1d-c7972b679bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aspecto_razao_boca(pontos_boca):\n",
    "    a = dist.euclidean(pontos_boca[3], pontos_boca[9])\n",
    "    b = dist.euclidean(pontos_boca[2], pontos_boca[10])\n",
    "    c = dist.euclidean(pontos_boca[4], pontos_boca[8])\n",
    "    d = dist.euclidean(pontos_boca[0], pontos_boca[6])\n",
    "    aspecto_razao = (a + b + c)/(3.0 * d)\n",
    "    return aspecto_razao"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3154294-1a66-403b-bd37-e9839964bfbd",
   "metadata": {},
   "source": [
    "Certo, agora vamos juntar tudo.\n",
    "\n",
    "Arredondei para 3 casas decimais o valor de aspecto de razão, para não ficar muito grande na leitura em tela.\n",
    "\n",
    "Note que peguei o primeiro ponto dos lábios e usei como referência para escrever o valor em tela.\n",
    "\n",
    "Usei o método A1 do numpy para converter em array somente o primeiro par de pontos, depois converti para uma tupla para enfim usar como parâmetro x e y do putText. Assim o valor fica logo abaixo da boca, por isso que coloquei a margem de 20 pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f8d25e1a-051f-4948-8bd1-fd29ece6cea7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interrompido\n"
     ]
    }
   ],
   "source": [
    "captura_video = cv2.VideoCapture(0)\n",
    "\n",
    "try:\n",
    "    while(True):\n",
    "        captura_ok, frame = captura_video.read()\n",
    "\n",
    "        if captura_ok:\n",
    "            frame = padronizar_imagem(frame)\n",
    "            pontos = pontos_marcos_faciais(frame)\n",
    "            if pontos is not None:\n",
    "                frame = anotar_marcos_faciais(frame, pontos)\n",
    "                pontos = pontos[0]\n",
    "                ar = aspecto_razao_boca(pontos[LABIO].tolist())\n",
    "                ar = round(ar,3)\n",
    "                coord = tuple(pontos[LABIO][0].A1.reshape(1, -1)[0])\n",
    "                coord = (coord[0], coord[1] + 20)\n",
    "                cv2.putText(frame, \"Aspecto Razao \" + str(ar), coord, cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,0), 2)\n",
    "\n",
    "            exibir_video(frame)\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    captura_video.release()\n",
    "    print(\"Interrompido\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d668820-25ad-4c8d-a349-b325539316a6",
   "metadata": {},
   "source": [
    "Faça um teste e veja o valor para sua boca de abertura que conseguiu obter. No meu caso, chegou aproximadamente em 0,5.\n",
    "\n",
    "Com isso, se a medida de aspecto de razão for maior que 0,5, vamos desenhar um retângulo.\n",
    "\n",
    "Para desenhar o retângulo tendo como base os pontos da boca, utilizamos o método boudingRect([pontos]).\n",
    "\n",
    "Depois, com as coordenadas, desenhamos o retângulo, ficando desta forma:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "999889d2-4788-468a-81fe-500585de945a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interrompido\n"
     ]
    }
   ],
   "source": [
    "captura_video = cv2.VideoCapture(0)\n",
    "\n",
    "try:\n",
    "    while(True):\n",
    "        captura_ok, frame = captura_video.read()\n",
    "\n",
    "        if captura_ok:\n",
    "            frame = padronizar_imagem(frame)\n",
    "            pontos = pontos_marcos_faciais(frame)\n",
    "            if pontos is not None:\n",
    "                frame = anotar_marcos_faciais(frame, pontos)\n",
    "                pontos = pontos[0]\n",
    "                ar = aspecto_razao_boca(pontos[LABIO].tolist())\n",
    "                ar = round(ar,3)\n",
    "\n",
    "                if ar > 0.5:\n",
    "                    (x, y, w, h) = cv2.boundingRect(pontos[LABIO])\n",
    "                    frame = cv2.rectangle(frame, (x,y), (x+w,y+h), (255,255,0), 2)\n",
    "\n",
    "                coord = tuple(pontos[LABIO][0].A1.reshape(1, -1)[0])\n",
    "                coord = (coord[0], coord[1] + 20)\n",
    "                cv2.putText(frame, \"Aspecto Razao \" + str(ar), coord, cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,0), 2)\n",
    "\n",
    "            exibir_video(frame)\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    captura_video.release()\n",
    "    print(\"Interrompido\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "50aeb6cb-7e58-4827-82ec-c80b0a7fd072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interrompido\n"
     ]
    }
   ],
   "source": [
    "captura_video = cv2.VideoCapture(0)\n",
    "\n",
    "try:\n",
    "    while(True):\n",
    "        captura_ok, frame = captura_video.read()\n",
    "\n",
    "        if captura_ok:\n",
    "            frame = padronizar_imagem(frame)\n",
    "            pontos = pontos_marcos_faciais(frame)\n",
    "            if pontos is not None:\n",
    "                #frame = anotar_marcos_faciais(frame, pontos)\n",
    "                pontos = pontos[0]\n",
    "                ar = aspecto_razao_boca(pontos[LABIO].tolist())\n",
    "                ar = round(ar,3)\n",
    "\n",
    "                if ar > 0.5:\n",
    "                    (x, y, w, h) = cv2.boundingRect(pontos[LABIO])\n",
    "                    frame = cv2.rectangle(frame, (x,y), (x+w,y+h), (255,255,0), 2)\n",
    "\n",
    "                coord = tuple(pontos[LABIO][0].A1.reshape(1, -1)[0])\n",
    "                coord = (coord[0], coord[1] + 20)\n",
    "                cv2.putText(frame, \"Aspecto Razao \" + str(ar), coord, cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,0), 2)\n",
    "\n",
    "            exibir_video(frame)\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    captura_video.release()\n",
    "    print(\"Interrompido\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "939a5fb2-3fca-436f-bfff-860eff01745d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aspecto_razao_boca(pontos_boca):\n",
    "    a = dist.euclidean(pontos_boca[3], pontos_boca[9])\n",
    "    b = dist.euclidean(pontos_boca[2], pontos_boca[10])\n",
    "    c = dist.euclidean(pontos_boca[4], pontos_boca[8])\n",
    "    d = dist.euclidean(pontos_boca[0], pontos_boca[6])\n",
    "\n",
    "    aspecto_razao = (a + b + c)/(3*d)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
