{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f45a5337-f4f1-4cbb-9ae9-05bc49574a59",
   "metadata": {},
   "source": [
    "[00:00] Parabéns! Vocês acabaram de concluir o Curso de Análise Facial. Não deixem de fazer os exercícios, eles foram elaborados para que vocês tenham uma experiência ainda melhor, além das aulas que vocês acabaram de assistir. Eles compreendem questões conceituais e até mesmo questões práticas, além do que já vimos por aqui.\n",
    "\n",
    "[00:17] Pessoal, vamos fazer uma pequena retrospectiva: esse curso na verdade foi uma mini jornada, concordam? Ou seja, começamos desde a instalação, do zero. Fomos no Anaconda, baixamos o Anaconda, instalamos o OpenCV, instalamos as bibliotecas adicionais para que vocês consigam fazer todos os exercícios e também acompanharem a aula sem ter problema nenhum para a instalação dos seus ambientes.\n",
    "\n",
    "[00:39] Posteriormente, inclusive fizemos uma pequena revisão de visão computacional, explicando um pouco sobre o espaço de cores - que as imagens coloridas, por exemplo, podem estar no espaço “RGB”, que é o mais comum que as aplicações utilizam para abrir imagens, especialmente o “pyplot”, que utilizamos bastante aqui.\n",
    "\n",
    "[01:00] Mas também que temos outro espaço de cor: o escala de cinza, que é aquele mais simples e só tem um único canal. É o que reconhecemos como o preto e branco das antigas televisões, só para citar um pouco do exemplo.\n",
    "\n",
    "[01:13] Depois disso começamos a analisar que uma imagem, por si só, tem muitos recursos, ou seja, tem regiões que interessam para nós, nosso curso, as faces é o que mais interessa.\n",
    "\n",
    "[01:25] Agora, nas questões de computador como nessa imagem: eu tenho um livro, eu tenho um fundo e tenho plantas. Isso não nos interessa, então precisamos fazer o quê? A extração e até mesmo nos concentrarmos nas regiões de interesse, que são os rostos.\n",
    "\n",
    "[01:39] Para fazer isso, podemos manualmente fazer um recorte da imagem, mas não isso resolve porque muitas imagens requerem algo automatizado.\n",
    "\n",
    "[01:46] Então por isso que recorremos aos classificadores. Por exemplo: o classificador de [CASCATA DE HAAR], que é excelente para segmentar região de interesse de qualquer imagem. Nesse caso, estamos usando o classificador que é focado em rosto frontal.\n",
    "\n",
    "[02:00] Mas no repositório do OpenCV, por exemplo, inclusive tem outros classificadores já treinados que vão desde placa de carro, pessoas de corpo completo, meio corpo, olhos, e tem até de gatos, que eu tinha comentado: “frontalcatface”.\n",
    "\n",
    "[02:17] “fullbody”, “russian_plate”, que seriam as placas dos carros russos, só para vocês entenderem como ele é robusto nesse tipo de detecção, então o Haar Cascade - esse tipo de classificador é um classificador de segmentação, ou seja, você vai rodar ele para separar a imagem que você vai trabalhar.\n",
    "\n",
    "[02:34] Para depois você pegar essa imagem e utilizar em algoritmos mais complexos, que foi o caso que vimos nas aulas seguintes, para podermos trabalhar na questão de criar e de construir um classificador.\n",
    "\n",
    "[02:45] Nós estudamos aqueles algoritmos, que são os Eigenfaces, FisherFaces e o LBPH, então com o Haar Cascade, com o classificador de [CASCATA DE HAAR], nós fazemos o quê? A segmentação da imagem para treinar ou até mesmo para poder inferir.\n",
    "\n",
    "[02:58] Essa imagem, por exemplo: aqui já trabalhamos com a imagem cortada mas se vocês pegassem o dataset completo, com a imagem de fundo, poderíamos simplesmente passar o Haar Cascade para ele nos fazer esse recorte.\n",
    "\n",
    "[03:09] E com isso trabalharmos para construir um classificador - e falando no classificador, também verificamos que não me adianta ter simplesmente as imagens e colocar em um classificador.\n",
    "\n",
    "[03:21] Eu preciso padronizá-las. Essa padronização, tanto é da parte de dimensão, eu só posso comparar coisas no mesmo tamanho, para não dar nenhuma distorção, e também espaço de cores.\n",
    "\n",
    "[03:32] Os três classificadores que utilizamos, pela robustez e velocidade que eles foram desenhados, eles trabalham simplesmente com imagens em escala de cinza, então não adianta colocar imagem colorida aqui porque ele não vai considerar essa informação diante de como eles foram desenhados.\n",
    "\n",
    "[03:46] Então na nossa etapa de pré-processamento que nós vimos, não só convertermos para a escala de cinza, como também reduzimos o tamanho dessas imagens.\n",
    "\n",
    "[03:54] E depois avançando, estudamos um pouco a biblioteca Dlib. A biblioteca Dlib é aquela onde já tem um modelo pré-treinado para extrair os marcos faciais. Os marcos faciais são os pontos que delimitam as regiões do rosto.\n",
    "\n",
    "[04:08] Por exemplo essa imagem aqui, o nós vemos são vários pontos e o conjunto de pontos, se unirmos esses pontos, vamos chegar na região do rosto, então temos os olhos, a boca, o nariz e o próprio rosto.\n",
    "\n",
    "[04:23] E com essas informações podemos fazer várias coisas, desde escolhermos um ponto central e medir a distância entre os demais pontos, até estabelecer características que me permitem construir um classificador de emoções, então se rirmos, geralmente fechamos o olho e abrimos o lábio aqui, a boca. Se ficamos sérios, mudam essas distâncias.\n",
    "\n",
    "[04:46] Então os marcos faciais ajudam desde obtermos aspectos geométricos do rosto - de você ter uma abertura e fechamento dos olhos e da boca - como também auxiliam nesses classificadores mais avançados de detecção de emoções. Com base nisso, fizemos alguns estudos, como nesse vídeo aqui, onde eu estou estudando a abertura e fechamento da boca.\n",
    "\n",
    "[05:08] Só que nesse caso, como eu estou pegando de uma câmera, temos aquela questão de escala: se eu aproximo ou afasto da câmera, o meu rosto fica grande ou ficar menor.\n",
    "\n",
    "[05:19] Se eu quero criar um detector de bocejo, por exemplo, eu tenho que criar um artifício que me permite ser invariante à escala, ou seja, se eu aproximar muito, me aproximar pouco, ou me afastar, a forma de identificar isso não pode ser afetada.\n",
    "\n",
    "[05:34] É para isso que usamos um conceito antigo de geometria, que é o que chamamos de aspecto de razão, onde eu pego as medidas da boca em relação ao seu comprimento e a sua altura e faço a razão delas. Esse número, ou seja, essa razão que eu uso para estabelecer um limiar de por exemplo, até 0.5 e 0.6. Eu entendo que essa boca está aberta.\n",
    "\n",
    "[05:57] Ou então, se eu pego um número menor, eu entendo que essa boca, por exemplo, está fechada. Com isso conseguimos criar os detectores, tanto de abertura de boca e para bocejo, quanto também para fechamento de olhos - para identificarmos que a pessoa está dormindo, por exemplo.\n",
    "\n",
    "[06:08] Enfim, temos uma série de ferramentas e classificadores, que construímos do zero e que tornam vocês capazes de criarem aplicações dentro desse universo. Desde de vocês criarem um sistema de identificação de rostos - seja para segurança ou até mesmo uma aplicação, que até estávamos falando de uma entrevista virtual.\n",
    "\n",
    "[06:27] Vocês podem, por exemplo, identificar se a pessoa está bocejando, se ela tá com olho aberto ou fechado, ver se ela está atenta e se ela está de fato por lá, então é um conjunto de ferramentas que habilitam vocês a construírem aplicações dessa natureza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d7fe34-15c8-4a13-83c8-cb8f1b802aac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
