{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b2c3bdd-4bb5-4d5e-a270-8449bfc609be",
   "metadata": {},
   "source": [
    "Vamos trabalhar com vídeos agora. Os vídeos nada mais são do que uma coleção de imagens, ou seja, se você pegar um vídeo de alguns segundos, cada segundo desse é composto por vários frames - que são quadros dessa imagem, onde podemos no OpenCV, trabalhar de forma separada para cada um desses frames.\n",
    "\n",
    "Por exemplo: para cada frame eu posso identificar uma face ou uma região de interesse ou coisas assim.\n",
    "\n",
    "Podemos não só abrir um vídeo que já foi previamente salvo, mas também referenciar a própria webcam, então vamos ver como isso funciona. Antes da avançarmos, precisamos só ter certeza se temos todas as bibliotecas necessárias.\n",
    "\n",
    "O OpenCV tem um método chamado “imshow” que até que funciona muito bem, só que somente no Windows ele costuma funcionar, ou seja, no macOS, se você chamar essa mesma função, ele costuma travar e não funciona de uma forma legal nesses dois ambientes.\n",
    "\n",
    "Somente no Windows que funciona de forma adequada portanto vamos preferir trabalhar com o Matplotlib e fazer o streaming do vídeo no próprio Matplotlib porque funciona bem em todas as plataformas: no Windows, no Mac e até mesmo no Linux, se for o caso.\n",
    "\n",
    "Independentemente disso, eu vou deixar aqui embaixo as instruções para utilizar o “imshow” para aqueles que tenham a plataforma Windows e prefiram trabalhar dessa forma, então como vamos trabalhar aqui de uma forma que independentemente de plataforma, vamos precisar importar algumas bibliotecas necessárias. Vou começar aqui com a biblioteca “io” do BytesIO - “from io import BytesIO”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2a521434-bc96-45e5-aee6-a6200abb997b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import dlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.spatial import distance as dist\n",
    "\n",
    "from io import BytesIO\n",
    "from IPython.display import clear_output, Image, display\n",
    "from PIL import Image as Img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4b0a0449-c413-4090-819e-5cdae464fddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "classificador_dlib_68_path = \"classificadores/shape_predictor_68_face_landmarks.dat\"\n",
    "classificador_dlib = dlib.shape_predictor(classificador_dlib_68_path)\n",
    "detector_face = dlib.get_frontal_face_detector()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3cc9007a-d5ac-4d7b-b995-b008004db908",
   "metadata": {},
   "outputs": [],
   "source": [
    "def padronizar_imagem(frame):\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    frame = cv2.resize(frame, (500,400))\n",
    "    return frame\n",
    "\n",
    "def exibir_video(frame):\n",
    "    img = Img.fromarray(frame, \"RGB\")\n",
    "    buffer = BytesIO()\n",
    "    img.save(buffer, format=\"JPEG\")\n",
    "    display(Image(data=buffer.getvalue()))\n",
    "    clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "49ddf164-4404-4f3b-ba6b-dc1ceb7188f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aspecto_razao_boca(pontos_boca):\n",
    "    a = dist.euclidean(pontos_boca[3], pontos_boca[9])\n",
    "    b = dist.euclidean(pontos_boca[2], pontos_boca[10])\n",
    "    c = dist.euclidean(pontos_boca[4], pontos_boca[8])\n",
    "    d = dist.euclidean(pontos_boca[0], pontos_boca[6])\n",
    "\n",
    "    aspecto_razao = (a + b + c)/(3*d)\n",
    "\n",
    "    return aspecto_razao "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3cbc2ec8-4a58-4a9d-8a45-f94693af4423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interrompido\n"
     ]
    }
   ],
   "source": [
    " captura_video = cv2.VideoCapture(\"videos/expressoes.mov\")\n",
    "\n",
    "try:\n",
    "    while(True):\n",
    "        captura_ok, frame = captura_video.read()\n",
    "\n",
    "        if captura_ok:\n",
    "            frame = padronizar_imagem(frame)\n",
    "            exibir_video(frame)\n",
    "            \n",
    "except KeyboardInterrupt:\n",
    "    captura_video.release()\n",
    "    print(\"Interrompido\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5983c2fc-3232-427b-9299-0f680eac2c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "FACE = list(range(17, 68))\n",
    "FACE_COMPLETA = list(range(0, 68))\n",
    "LABIO = list(range(48, 61))\n",
    "SOMBRANCELHA_DIRETA = list(range(17, 22))\n",
    "SOMBRANCELHA_ESQUERDA = list(range(22, 27))\n",
    "OLHO_DIREITO = list(range(36,42))\n",
    "OLHO_ESQUERDO = list(range(42,48))\n",
    "NARIZ = list(range(27,35))\n",
    "MANDIBULA = list(range(0,17))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2e7d6636-d31d-46fc-9305-cef41b7c29df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def anotar_marcos_casca_convexa_boca(imagem, marcos):\n",
    "    retangulos = detector_face(imagem, 1)\n",
    "\n",
    "    if len(retangulos) == 0:\n",
    "        return None\n",
    "    for idx, ret in enumerate(retangulos):\n",
    "        marco = marcos[idx]\n",
    "\n",
    "        pontos = cv2.convexHull(marco[LABIO])\n",
    "        cv2.drawContours(imagem, [pontos], 0, (0,255,0), 2)\n",
    "\n",
    "    return imagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2accac71-b29c-4399-aadb-ff202fa35f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def anotar_marcos_casca_convexa_olhos(imagem, marcos):\n",
    "    retangulos = detector_face(imagem, 1)\n",
    "\n",
    "    if len(retangulos) == 0:\n",
    "        return None\n",
    "    for idx, ret in enumerate(retangulos):\n",
    "        marco = marcos[idx]\n",
    "\n",
    "        pontos = cv2.convexHull(marco[OLHO_ESQUERDO])\n",
    "        cv2.drawContours(imagem, [pontos], 0, (0,255,0), 2)\n",
    "\n",
    "        pontos = cv2.convexHull(marco[OLHO_DIREITO])\n",
    "        cv2.drawContours(imagem, [pontos], 0, (0,255,0), 2)\n",
    "\n",
    "    return imagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7fa91ac5-a2de-4142-92d1-f0124c513de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pontos_marcos_faciais(imagem):\n",
    "    retangulos = detector_face(imagem, 1)\n",
    "    \n",
    "    if len(retangulos) == 0:\n",
    "        return None\n",
    "    \n",
    "    marcos = []\n",
    "    \n",
    "    for ret in retangulos:\n",
    "        marcos.append(np.matrix([[p.x, p.y] for p in classificador_dlib(imagem,ret).parts()]))\n",
    "    \n",
    "    return marcos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "231dd252-3378-4551-b8af-883b83fd6e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aspecto_razao_olhos(pontos_olhos):\n",
    "    a = dist.euclidean(pontos_olhos[1], pontos_olhos[5])\n",
    "    b = dist.euclidean(pontos_olhos[2], pontos_olhos[4])\n",
    "    c = dist.euclidean(pontos_olhos[0], pontos_olhos[3])\n",
    "\n",
    "    aspecto_razao = (a+b)/(2*c)\n",
    "    return aspecto_razao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bbc90211-b1f0-4c5a-bf2b-afc7c45b5d92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interrompido\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    ar_max = 0\n",
    "    video = cv2.VideoCapture(\"videos/bocejo.mov\")\n",
    "    while(True):\n",
    "        captura_ok, frame = video.read()\n",
    "        if captura_ok:\n",
    "            frame = padronizar_imagem(frame)\n",
    "            marcos_faciais = pontos_marcos_faciais(frame)\n",
    "            \n",
    "            if marcos_faciais is not None:\n",
    "                ar_boca = aspecto_razao_boca(marcos_faciais[0][LABIO].tolist())\n",
    "                ar_boca = round(ar_boca, 3)\n",
    "                \n",
    "                if ar_boca > ar_max:\n",
    "                    ar_max = ar_boca\n",
    "                \n",
    "                info = \"boca \" + str(ar_boca) + \" maximo \" + str(ar_max)\n",
    "                \n",
    "                frame = anotar_marcos_casca_convexa_boca(frame, marcos_faciais)\n",
    "                cv2.putText(frame, info, (20, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,0), 2)\n",
    "            \n",
    "            exibir_video(frame)\n",
    "            \n",
    "except KeyboardInterrupt:\n",
    "    video.release()\n",
    "    print(\"Interrompido\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "37a6537e-0646-4290-ac46-95587c60ba1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interrompido\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    ar_min_esquerdo = 1\n",
    "    ar_min_direito = 1\n",
    "    #video = cv2.VideoCapture(\"videos/olhos-fechados.mov\")\n",
    "    video = cv2.VideoCapture(0)\n",
    "    while(True):\n",
    "        captura_ok, frame = video.read()\n",
    "        if captura_ok:\n",
    "            frame = padronizar_imagem(frame)\n",
    "            marcos_faciais = pontos_marcos_faciais(frame)\n",
    "            \n",
    "            if marcos_faciais is not None:\n",
    "                ar_olho_esquerdo = aspecto_razao_olhos(marcos_faciais[0][OLHO_ESQUERDO].tolist())\n",
    "                ar_olho_esquerdo = round(ar_olho_esquerdo, 3)\n",
    "\n",
    "                ar_olho_direito = aspecto_razao_olhos(marcos_faciais[0][OLHO_DIREITO].tolist())\n",
    "                ar_olho_direito = round(ar_olho_direito, 3)\n",
    "                \n",
    "                if ar_min_esquerdo > ar_olho_esquerdo:\n",
    "                    ar_min_esquerdo = ar_olho_esquerdo\n",
    "\n",
    "                if ar_min_direito > ar_olho_direito:\n",
    "                    ar_min_direito = ar_olho_direito\n",
    "\n",
    "                info_oe = \"olho esquerdo \" + str(ar_olho_esquerdo) + \" minimo \" + str(ar_min_esquerdo)\n",
    "                info_od = \"olho direito \" + str(ar_olho_direito) + \" minimo \" + str(ar_min_direito)\n",
    "                \n",
    "                frame = anotar_marcos_casca_convexa_olhos(frame, marcos_faciais)\n",
    "                cv2.putText(frame, info_oe, (20, 50), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,0), 2)\n",
    "                cv2.putText(frame, info_od, (20, 80), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,0), 2)\n",
    "            \n",
    "            exibir_video(frame)\n",
    "            \n",
    "except KeyboardInterrupt:\n",
    "    video.release()\n",
    "    print(\"Interrompido\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "10357b01-5d5b-4418-be4a-6850488c7817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Interrompido\n"
     ]
    }
   ],
   "source": [
    "captura_video = cv2.VideoCapture(\"videos/bocejo.mov\")\n",
    "\n",
    "try:\n",
    "    aspecto_razao_max = 0\n",
    "    qtde_bocejo = 0\n",
    "\n",
    "    bocejo = False\n",
    "    bocejo_anterior = False\n",
    "\n",
    "    while(True):\n",
    "        captura_ok, frame = captura_video.read()\n",
    "\n",
    "        if captura_ok:\n",
    "            frame = padronizar_imagem(frame)\n",
    "            pontos = pontos_marcos_faciais(frame)\n",
    "\n",
    "            if pontos is not None:\n",
    "\n",
    "                aspecto_razao = aspecto_razao_boca(pontos[0][LABIO].tolist())\n",
    "                aspecto_razao = round(aspecto_razao, 3)\n",
    "\n",
    "                if aspecto_razao > aspecto_razao_max:\n",
    "                    aspecto_razao_max = aspecto_razao\n",
    "\n",
    "                aspecto_razao_info = \"aspecto razao \" + str(aspecto_razao) + \" maximo \" + str(aspecto_razao_max)\n",
    "\n",
    "\n",
    "                coord = tuple(pontos[0][LABIO][0].A1.reshape(1, -1)[0])\n",
    "                coord = (coord[0] + 20, coord[1] + 20)\n",
    "\n",
    "                cv2.putText(frame, aspecto_razao_info, coord, cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,0), 2)\n",
    "\n",
    "                if aspecto_razao > 1.0:\n",
    "                    bocejo = True\n",
    "                else:\n",
    "                    bocejo = False\n",
    "\n",
    "                if bocejo_anterior == False and bocejo == True:\n",
    "                    qtde_bocejo += 1\n",
    "\n",
    "                coord = (coord[0], coord[1] + 23)\n",
    "                cv2.putText(frame, \"bocejos \" + str(qtde_bocejo), coord, cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,0,0), 2)\n",
    "\n",
    "                bocejo_anterior = bocejo\n",
    "\n",
    "            exibir_video(frame)\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    captura_video.release()\n",
    "    print(\"Interrompido\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9b7a14-2055-48d7-a62b-ed2f21b20160",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
